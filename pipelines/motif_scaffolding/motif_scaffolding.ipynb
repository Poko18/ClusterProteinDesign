{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Submitting 100 jobs to the cluster, generating 10 diffusions\n",
      "ðŸ”„ In total, 1000 RF diffusions will be generated.\n",
      "ðŸ”¬ For each diffusion, 24 MPNN sequences will be evaluated, resulting in 24000 sequences validated with AF2.\n"
     ]
    }
   ],
   "source": [
    "input_prefix = \"1vmg\"\n",
    "input_pdb = \"input/1vmg.pdb\"\n",
    "output_dir = f\"output/{input_prefix}\"\n",
    "script_dir = f\"{output_dir}/scripts\"\n",
    "\n",
    "### Slurm params\n",
    "num_jobs = 100\n",
    "array_limit = 5\n",
    "\n",
    "### RFdiffusion params\n",
    "diffuser_T = 100\n",
    "diffusions_per_job = 10\n",
    "\n",
    "fill_contigs = f\"30-100/A35-57/30-100\"\n",
    "inpaint_seq = \"A36-53\"\n",
    "total_len = \"80-200\"\n",
    "\n",
    "input_pdb_as = \"A35,A54-57\"\n",
    "\n",
    "### MPNN params\n",
    "num_seqs = 24\n",
    "mpnn_batch = 8\n",
    "sampling_temp = 0.1\n",
    "rm_aa = \"C\"\n",
    "soluble = True\n",
    "\n",
    "### AF2 params\n",
    "recycles = 6\n",
    "multimer = False\n",
    "initial_guess = False\n",
    "\n",
    "print(f\"ðŸ”„ Submitting {num_jobs} jobs to the cluster, generating {diffusions_per_job} diffusions\")\n",
    "print(f\"ðŸ”„ In total, {num_jobs*diffusions_per_job} RF diffusions will be generated.\")\n",
    "print(f\"ðŸ”¬ For each diffusion, {num_seqs} MPNN sequences will be evaluated, resulting in {num_jobs*diffusions_per_job*num_seqs} sequences validated with AF2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run motif scaffolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”— Generated 100 contigs.. example: 46-46/A35-57/57-57\n"
     ]
    }
   ],
   "source": [
    "def generate_contig_strings(num_jobs: int, fill_contigs: str, total_len_range: str) -> list:\n",
    "    \"\"\"Generates a list of contig strings based on input ranges and length constraints.\"\"\"\n",
    "\n",
    "    total_len_min, total_len_max = map(int, total_len_range.split(\"-\"))\n",
    "    contig_parts = fill_contigs.split(\"/\")\n",
    "    contig_strings = []\n",
    "\n",
    "    while len(contig_strings) < num_jobs:\n",
    "        contig_list = []\n",
    "        total_sum = 0\n",
    "\n",
    "        for part in contig_parts:\n",
    "            if \"-\" in part and part.replace(\"-\", \"\").isdigit():\n",
    "                start, end = map(int, part.split(\"-\"))\n",
    "                value = random.randint(start, end)\n",
    "                total_sum += value\n",
    "                contig_list.append(f\"{value}-{value}\")\n",
    "            else:\n",
    "                int_part = part[1:]\n",
    "                start, end = map(int, int_part.split(\"-\"))\n",
    "                value = end - start\n",
    "                total_sum += value\n",
    "                contig_list.append(part)\n",
    "\n",
    "        if total_len_min <= total_sum <= total_len_max:\n",
    "            contig_strings.append(\"/\".join(contig_list))\n",
    "\n",
    "    return contig_strings\n",
    "\n",
    "contig_strings = generate_contig_strings(num_jobs, fill_contigs, str(total_len))\n",
    "print(f\"ðŸ”— Generated {len(contig_strings)} contigs.. example: {contig_strings[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for i, contig in enumerate(contig_strings):\n",
    "    contigs_list = contig.split(\" \")\n",
    "    contigs_str = \":\".join(contigs_list)\n",
    "    initial_guess_flag = \"--initial_guess\" if initial_guess else \"\"\n",
    "    multimer_flag = \"--multimer\" if multimer else \"\"\n",
    "    soluble_flag = \"--use_soluble\" if soluble else \"\"\n",
    "    rf_output_dir = f\"{output_dir}/rf/rf_{i}\"\n",
    "    af_output_dir = f\"{output_dir}/af/af_{i}\"\n",
    "    script = f\"\"\"#!/bin/bash\n",
    "#SBATCH --partition=gpu\n",
    "#SBATCH --gres=gpu:A40:1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --array=0-{num_jobs-1}%{array_limit}\n",
    "#SBATCH --job-name=motif_{input_prefix}\n",
    "\n",
    "set -e\n",
    "# Load Anaconda environment\n",
    "source /home/tsatler/anaconda3/etc/profile.d/conda.sh\n",
    "\n",
    "# Activate Rosetta environment\n",
    "echo Metal binding scaffold guided RFdiffusion\n",
    "conda activate SE3nv\n",
    "\n",
    "python /home/tsatler/RFdif/RFdiffusion/scripts/run_inference.py \\\n",
    "        diffuser.T={diffuser_T} \\\n",
    "        'contigmap.contigs=[{contig}]' \\\n",
    "        'contigmap.inpaint_seq=[A36-53]' \\\n",
    "        \"inference.output_prefix={rf_output_dir}\" \\\n",
    "        inference.input_pdb={input_pdb} \\\n",
    "        inference.num_designs={diffusions_per_job} \\\n",
    "        inference.ckpt_override_path=/home/tsatler/RFdif/RFdiffusion/models/ActiveSite_ckpt.pt\n",
    "\n",
    "# Validate with AF2\n",
    "echo Validate with AF2\n",
    "conda activate colabdesign\n",
    "\n",
    "input_pdbs=(\"{rf_output_dir}\"/*.pdb)\n",
    "script=\"/home/tsatler/RFdif/ClusterProteinDesign/scripts/metalbinding/scripts/motif_design.py\"\n",
    "mkdir -p {af_output_dir}\n",
    "\n",
    "for ((i=0; i<${{#input_pdbs[@]}}; i++)); do\n",
    "    pdb=${{input_pdbs[i]}}\n",
    "    echo \"Processing $pdb...\"\n",
    "    \n",
    "    python $script $pdb {af_output_dir} {contigs_str} \\\n",
    "            --input_pdb {input_pdb} \\\n",
    "            --input_pdb_as {input_pdb_as} \\\n",
    "            --num_seqs {num_seqs} \\\n",
    "            --sampling_temp {sampling_temp} \\\n",
    "            --num_recycles {recycles} \\\n",
    "            --rm_aa={rm_aa} \\\n",
    "            --mpnn_batch {mpnn_batch} \\\n",
    "            --results_dataframe {output_dir}/df \\\n",
    "            --save_best_only \\\n",
    "            {initial_guess_flag} {multimer_flag} {soluble_flag}\n",
    "done\n",
    "\n",
    "\"\"\"\n",
    "    os.makedirs(script_dir, exist_ok=True)\n",
    "    with open(f\"{script_dir}/job_{i}.sh\", \"w\") as f:\n",
    "        f.write(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create run script\n",
    "run_script = f\"\"\"#!/bin/bash\n",
    "#SBATCH --partition=gpu\n",
    "#SBATCH --gres=gpu:A40:1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --array=0-{num_jobs-1}%{array_limit}\n",
    "#SBATCH --job-name=motif_{input_prefix}\n",
    "\n",
    "set -e\n",
    "\n",
    "input_commands=({script_dir}/*.sh)\n",
    "command_file=${{input_commands[$SLURM_ARRAY_TASK_ID]}}\n",
    "# mapfile -t commands < \"$command_file\"\n",
    "\n",
    "echo \"Running command file: $command_file\"                   \n",
    "bash $command_file\n",
    "\n",
    "\"\"\"\n",
    "with open(f\"{output_dir}/run.sh\", \"w\") as f:\n",
    "    f.write(run_script)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Submitting jobs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: error: Batch job submission failed: Invalid account or account/partition combination specified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='sbatch output/1vmg/run.sh', returncode=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"ðŸš€ Submitting jobs...\")\n",
    "subprocess.run(f\"sbatch {output_dir}/run.sh\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n"
     ]
    }
   ],
   "source": [
    "!squeue --me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colabthread",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
